#!/usr/bin/env python3
"""
Comprehensive test suite for queue management system
Tests normal operations, error handling, load testing, and admin endpoints
"""
import asyncio
import aiohttp
import json
import time
import uuid
from datetime import datetime, timezone
from typing import List, Dict
import random

BASE_URL = "http://localhost:8001"

class QueueSystemTester:
    def __init__(self):
        self.test_results = []
        self.session = None
        
    async def setup(self):
        """Setup test environment"""
        self.session = aiohttp.ClientSession()
        
    async def teardown(self):
        """Cleanup test environment"""
        if self.session:
            await self.session.close()
    
    def generate_test_points(self, count: int, flight_uuid: str = None) -> List[Dict]:
        """Generate test track points"""
        points = []
        base_lat = 37.333
        base_lon = -122.05
        
        for i in range(count):
            point = {
                'datetime': datetime.now(timezone.utc).isoformat(),
                'flight_uuid': flight_uuid or str(uuid.uuid4()),
                'flight_id': f'test-flight-{uuid.uuid4().hex[:8]}',
                'lat': base_lat + (i * 0.0001),
                'lon': base_lon + (i * 0.0001),
                'elevation': 1000 + (i * 10)
            }
            points.append(point)
        
        return points
    
    async def test_health_check(self):
        """Test 1: Basic health check"""
        print("\nğŸ§ª Test 1: Health Check")
        try:
            async with self.session.get(f"{BASE_URL}/health") as resp:
                data = await resp.json()
                status = data.get('status')
                db_status = data.get('database', {}).get('status')
                redis_status = data.get('redis', {}).get('status')
                
                print(f"  âœ… Health status: {status}")
                print(f"  âœ… Database: {db_status}")
                print(f"  âœ… Redis: {redis_status}")
                
                self.test_results.append({
                    'test': 'health_check',
                    'passed': status == 'healthy',
                    'details': data
                })
                return status == 'healthy'
        except Exception as e:
            print(f"  âŒ Health check failed: {e}")
            self.test_results.append({
                'test': 'health_check',
                'passed': False,
                'error': str(e)
            })
            return False
    
    async def test_queue_admin_endpoints(self):
        """Test 2: Admin endpoints"""
        print("\nğŸ§ª Test 2: Queue Admin Endpoints")
        
        tests_passed = 0
        tests_total = 4
        
        # Test queue health endpoint
        try:
            async with self.session.get(f"{BASE_URL}/admin/queue/health") as resp:
                data = await resp.json()
                print(f"  âœ… Queue health endpoint works")
                print(f"     Status: {data.get('status')}")
                tests_passed += 1
        except Exception as e:
            print(f"  âŒ Queue health failed: {e}")
        
        # Test queue stats endpoint
        try:
            async with self.session.get(f"{BASE_URL}/admin/queue/stats") as resp:
                data = await resp.json()
                print(f"  âœ… Queue stats endpoint works")
                summary = data.get('summary', {})
                print(f"     Total pending: {summary.get('total_pending', 0)}")
                print(f"     Total DLQ: {summary.get('total_dlq', 0)}")
                tests_passed += 1
        except Exception as e:
            print(f"  âŒ Queue stats failed: {e}")
        
        # Test cleanup endpoint (dry run)
        try:
            async with self.session.post(
                f"{BASE_URL}/admin/queue/cleanup",
                params={'max_age_hours': 24, 'dry_run': True}
            ) as resp:
                data = await resp.json()
                print(f"  âœ… Cleanup endpoint works (dry run)")
                tests_passed += 1
        except Exception as e:
            print(f"  âŒ Cleanup failed: {e}")
        
        # Test force process endpoint
        try:
            async with self.session.post(
                f"{BASE_URL}/admin/queue/force-process/live_points",
                params={'batch_size': 10}
            ) as resp:
                data = await resp.json()
                print(f"  âœ… Force process endpoint works")
                print(f"     Items processed: {data.get('items_retrieved', 0)}")
                tests_passed += 1
        except Exception as e:
            print(f"  âŒ Force process failed: {e}")
        
        self.test_results.append({
            'test': 'admin_endpoints',
            'passed': tests_passed == tests_total,
            'score': f"{tests_passed}/{tests_total}"
        })
        
        return tests_passed == tests_total
    
    async def test_queue_with_valid_flight(self):
        """Test 3: Queue points with valid flight reference"""
        print("\nğŸ§ª Test 3: Queue Points with Valid Flight")
        
        # First, we need to get or create a valid flight
        # For testing, we'll check existing flights
        try:
            # Get races to find a valid race_id
            async with self.session.get(f"{BASE_URL}/api/races") as resp:
                if resp.status == 200:
                    races = await resp.json()
                    if races and len(races) > 0:
                        race_id = races[0].get('id')
                        print(f"  Using race_id: {race_id}")
                        
                        # Try to get flights for this race
                        async with self.session.get(f"{BASE_URL}/api/race/{race_id}/flights") as flight_resp:
                            if flight_resp.status == 200:
                                flights = await flight_resp.json()
                                if flights and len(flights) > 0:
                                    flight_uuid = flights[0].get('uuid')
                                    print(f"  Using existing flight_uuid: {flight_uuid}")
                                else:
                                    print(f"  No flights found, will use test UUID")
                                    flight_uuid = str(uuid.uuid4())
                            else:
                                flight_uuid = str(uuid.uuid4())
                    else:
                        print("  No races found, using test UUID")
                        flight_uuid = str(uuid.uuid4())
                else:
                    flight_uuid = str(uuid.uuid4())
                    
        except Exception as e:
            print(f"  Could not get flight info: {e}")
            flight_uuid = str(uuid.uuid4())
        
        # Generate test points
        points = self.generate_test_points(10, flight_uuid)
        
        # Queue points via API (simulate what the tracking endpoint would do)
        # Since we're testing the queue system, we'll add directly to Redis
        from redis.asyncio import Redis
        from config import settings
        
        redis_url = settings.get_redis_url()
        redis = await Redis.from_url(redis_url, decode_responses=True)
        
        try:
            # Add to priority queue
            queue_item = {
                'points': points,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'count': len(points),
                'queue_type': 'live_points'
            }
            
            await redis.zadd(
                "queue:live_points",
                {json.dumps(queue_item): 0}
            )
            
            print(f"  âœ… Queued {len(points)} points")
            
            # Wait for processing
            await asyncio.sleep(2)
            
            # Check if processed
            queue_size = await redis.zcard("queue:live_points")
            dlq_size = await redis.zcard("dlq:live_points")
            
            print(f"  Queue size after processing: {queue_size}")
            print(f"  DLQ size: {dlq_size}")
            
            # If flight doesn't exist, points should be in DLQ
            if dlq_size > 0:
                print(f"  âš ï¸  Points moved to DLQ (expected if flight doesn't exist)")
            
            self.test_results.append({
                'test': 'valid_flight_queue',
                'passed': True,
                'queue_size': queue_size,
                'dlq_size': dlq_size
            })
            
            await redis.aclose()
            return True
            
        except Exception as e:
            print(f"  âŒ Queue test failed: {e}")
            self.test_results.append({
                'test': 'valid_flight_queue',
                'passed': False,
                'error': str(e)
            })
            await redis.aclose()
            return False
    
    async def test_foreign_key_validation(self):
        """Test 4: Foreign key validation (invalid flight UUID)"""
        print("\nğŸ§ª Test 4: Foreign Key Validation")
        
        # Generate points with invalid flight UUID
        invalid_uuid = "00000000-0000-0000-0000-000000000000"
        points = self.generate_test_points(5, invalid_uuid)
        
        from redis.asyncio import Redis
        from config import settings
        
        redis_url = settings.get_redis_url()
        redis = await Redis.from_url(redis_url, decode_responses=True)
        
        try:
            # Clear DLQ first
            await redis.delete("dlq:live_points")
            
            # Add to queue
            queue_item = {
                'points': points,
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'count': len(points),
                'queue_type': 'live_points'
            }
            
            await redis.zadd(
                "queue:live_points",
                {json.dumps(queue_item): 0}
            )
            
            print(f"  âœ… Queued {len(points)} points with invalid flight UUID")
            
            # Force process to trigger validation (use correct queue type)
            async with self.session.post(
                f"{BASE_URL}/admin/queue/force-process/live",
                params={'batch_size': 10}
            ) as resp:
                data = await resp.json()
                print(f"  Processing triggered: {data}")
            
            # Wait for processing
            await asyncio.sleep(3)
            
            # Check DLQ
            dlq_size = await redis.zcard("dlq:live_points")
            queue_size = await redis.zcard("queue:live_points")
            
            print(f"  DLQ size after processing: {dlq_size}")
            print(f"  Queue size after processing: {queue_size}")
            
            # With enhanced processor, invalid points should be in DLQ
            if dlq_size > 0:
                print(f"  âœ… Invalid points correctly moved to DLQ")
                test_passed = True
            else:
                print(f"  âš ï¸  Points may have been processed or dropped")
                test_passed = queue_size == 0
            
            self.test_results.append({
                'test': 'foreign_key_validation',
                'passed': test_passed,
                'dlq_size': dlq_size
            })
            
            await redis.aclose()
            return test_passed
            
        except Exception as e:
            print(f"  âŒ FK validation test failed: {e}")
            self.test_results.append({
                'test': 'foreign_key_validation',
                'passed': False,
                'error': str(e)
            })
            await redis.aclose()
            return False
    
    async def test_load_testing(self):
        """Test 5: Load testing with concurrent requests"""
        print("\nğŸ§ª Test 5: Load Testing")
        
        from redis.asyncio import Redis
        from config import settings
        
        redis_url = settings.get_redis_url()
        redis = await Redis.from_url(redis_url, decode_responses=True)
        
        # Number of concurrent batches
        num_batches = 50
        points_per_batch = 100
        
        print(f"  Sending {num_batches} batches of {points_per_batch} points each")
        print(f"  Total points: {num_batches * points_per_batch}")
        
        try:
            # Clear queues first
            await redis.delete("queue:live_points")
            await redis.delete("dlq:live_points")
            
            # Generate and queue all batches concurrently
            start_time = time.time()
            
            tasks = []
            for i in range(num_batches):
                # Mix of valid and invalid UUIDs
                if i % 5 == 0:
                    flight_uuid = "00000000-0000-0000-0000-000000000000"  # Invalid
                else:
                    flight_uuid = str(uuid.uuid4())  # Random (probably invalid)
                
                points = self.generate_test_points(points_per_batch, flight_uuid)
                
                queue_item = {
                    'points': points,
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'count': len(points),
                    'queue_type': 'live_points',
                    'batch_id': i
                }
                
                task = redis.zadd(
                    "queue:live_points",
                    {json.dumps(queue_item): i}  # Use batch number as priority
                )
                tasks.append(task)
            
            await asyncio.gather(*tasks)
            
            queue_time = time.time() - start_time
            print(f"  âœ… Queued all batches in {queue_time:.2f} seconds")
            print(f"  Rate: {(num_batches * points_per_batch) / queue_time:.0f} points/second")
            
            # Close and reopen Redis to avoid connection pool issues
            await redis.aclose()
            await asyncio.sleep(1)
            redis = await Redis.from_url(redis_url, decode_responses=True)
            
            # Check initial queue size
            initial_size = await redis.zcard("queue:live_points")
            print(f"  Initial queue size: {initial_size}")
            
            # Force process multiple times to simulate continuous processing
            process_start = time.time()
            processed_batches = 0
            
            for _ in range(5):  # Process 5 times
                async with self.session.post(
                    f"{BASE_URL}/admin/queue/force-process/live",  # Fixed queue type
                    params={'batch_size': 500}
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        processed_batches += data.get('items_retrieved', 0)
                
                await asyncio.sleep(1)
            
            process_time = time.time() - process_start
            
            # Final statistics
            final_queue_size = await redis.zcard("queue:live_points")
            dlq_size = await redis.zcard("dlq:live_points")
            
            print(f"\n  ğŸ“Š Load Test Results:")
            print(f"     Queue time: {queue_time:.2f}s")
            print(f"     Process time: {process_time:.2f}s")
            print(f"     Batches processed: {processed_batches}")
            print(f"     Final queue size: {final_queue_size}")
            print(f"     DLQ size: {dlq_size}")
            print(f"     Success rate: {((initial_size - final_queue_size - dlq_size) / initial_size * 100):.1f}%")
            
            self.test_results.append({
                'test': 'load_testing',
                'passed': True,
                'total_points': num_batches * points_per_batch,
                'queue_time': queue_time,
                'process_time': process_time,
                'final_queue_size': final_queue_size,
                'dlq_size': dlq_size
            })
            
            await redis.aclose()
            return True
            
        except Exception as e:
            print(f"  âŒ Load test failed: {e}")
            self.test_results.append({
                'test': 'load_testing',
                'passed': False,
                'error': str(e)
            })
            await redis.aclose()
            return False
    
    async def test_concurrent_api_calls(self):
        """Test 6: Concurrent API calls"""
        print("\nğŸ§ª Test 6: Concurrent API Calls")
        
        num_concurrent = 20
        
        async def make_health_check():
            try:
                async with self.session.get(f"{BASE_URL}/health") as resp:
                    return resp.status == 200
            except:
                return False
        
        async def make_stats_check():
            try:
                async with self.session.get(f"{BASE_URL}/admin/queue/stats") as resp:
                    return resp.status == 200
            except:
                return False
        
        print(f"  Making {num_concurrent} concurrent requests to multiple endpoints")
        
        start_time = time.time()
        
        # Mix of different endpoint calls
        tasks = []
        for i in range(num_concurrent):
            if i % 2 == 0:
                tasks.append(make_health_check())
            else:
                tasks.append(make_stats_check())
        
        results = await asyncio.gather(*tasks)
        
        elapsed = time.time() - start_time
        successful = sum(1 for r in results if r)
        
        print(f"  âœ… Completed {num_concurrent} requests in {elapsed:.2f}s")
        print(f"  Success rate: {successful}/{num_concurrent} ({successful/num_concurrent*100:.1f}%)")
        print(f"  Requests per second: {num_concurrent/elapsed:.1f}")
        
        self.test_results.append({
            'test': 'concurrent_api_calls',
            'passed': successful == num_concurrent,
            'successful': successful,
            'total': num_concurrent,
            'rps': num_concurrent/elapsed
        })
        
        return successful == num_concurrent
    
    async def test_dlq_processing(self):
        """Test 7: DLQ reprocessing"""
        print("\nğŸ§ª Test 7: Dead Letter Queue Processing")
        
        try:
            # Check current DLQ size
            async with self.session.get(f"{BASE_URL}/admin/queue/stats") as resp:
                data = await resp.json()
                initial_dlq = data.get('summary', {}).get('total_dlq', 0)
                print(f"  Initial DLQ size: {initial_dlq}")
            
            if initial_dlq > 0:
                # Try to reprocess DLQ
                print(f"  Attempting to reprocess DLQ items...")
                
                async with self.session.post(
                    f"{BASE_URL}/admin/queue/process-dlq/live",  # Fixed queue type
                    params={'dry_run': False}
                ) as resp:
                    data = await resp.json()
                    result = data.get('result', {})
                    print(f"  Processed: {result.get('processed', 0)}")
                    print(f"  Failed: {result.get('failed', 0)}")
                    print(f"  Remaining: {result.get('remaining', 0)}")
            else:
                print(f"  No items in DLQ to process")
            
            self.test_results.append({
                'test': 'dlq_processing',
                'passed': True,
                'initial_dlq': initial_dlq
            })
            return True
            
        except Exception as e:
            print(f"  âŒ DLQ test failed: {e}")
            self.test_results.append({
                'test': 'dlq_processing',
                'passed': False,
                'error': str(e)
            })
            return False
    
    async def cleanup_test_data(self):
        """Clean up test data"""
        print("\nğŸ§¹ Cleaning up test data...")
        
        try:
            # Clear test queues
            async with self.session.delete(
                f"{BASE_URL}/admin/queue/clear/live",  # Fixed queue type
                params={'include_dlq': True, 'confirm': True}
            ) as resp:
                if resp.status == 200:
                    print("  âœ… Cleared live_points queue and DLQ")
                else:
                    print(f"  âš ï¸  Clear returned status {resp.status}")
                    
        except Exception as e:
            print(f"  âŒ Cleanup failed: {e}")
    
    async def run_all_tests(self):
        """Run all tests"""
        print("=" * 60)
        print("ğŸš€ QUEUE SYSTEM COMPREHENSIVE TEST SUITE")
        print("=" * 60)
        
        await self.setup()
        
        try:
            # Run all tests
            await self.test_health_check()
            await self.test_queue_admin_endpoints()
            await self.test_queue_with_valid_flight()
            await self.test_foreign_key_validation()
            await self.test_load_testing()
            await self.test_concurrent_api_calls()
            await self.test_dlq_processing()
            
            # Cleanup
            await self.cleanup_test_data()
            
            # Print summary
            print("\n" + "=" * 60)
            print("ğŸ“‹ TEST SUMMARY")
            print("=" * 60)
            
            total_tests = len(self.test_results)
            passed_tests = sum(1 for t in self.test_results if t['passed'])
            
            for result in self.test_results:
                status = "âœ…" if result['passed'] else "âŒ"
                print(f"{status} {result['test']}")
                if 'error' in result:
                    print(f"   Error: {result['error']}")
            
            print(f"\nğŸ“Š Overall: {passed_tests}/{total_tests} tests passed")
            
            if passed_tests == total_tests:
                print("ğŸ‰ ALL TESTS PASSED!")
            else:
                print(f"âš ï¸  {total_tests - passed_tests} tests failed")
            
        finally:
            await self.teardown()


async def main():
    tester = QueueSystemTester()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())